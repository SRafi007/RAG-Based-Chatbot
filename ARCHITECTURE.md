# RAG-based Chatbot Architecture

## üìã Overview

This is a RAG (Retrieval-Augmented Generation) based chatbot built with LangGraph for company policy questions. The system uses a multi-agent architecture with plug-and-play capabilities.

## üèóÔ∏è Architecture

### High-Level Workflow

```
User Query
    ‚Üì
DomainGuard (Policy Scope Checker)
    ‚Üì
Router (LangGraph Conditional Edge)
    ‚Üì
    ‚îú‚îÄ‚Üí "off-topic" ‚Üí SummarizerAgent ‚Üí END
    ‚îÇ                      ‚Üì
    ‚îÇ                 Soft Refusal + Warning
    ‚îÇ
    ‚îî‚îÄ‚Üí "policy-related" ‚Üí RetrieverAgent ‚Üí SummarizerAgent ‚Üí END
                              ‚Üì                    ‚Üì
                         Retrieve Docs        Generate Answer
```

### Directory Structure

```
app/
‚îú‚îÄ‚îÄ orchestrator/              # LangGraph-based orchestration
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ state.py              # AgentState TypedDict
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py       # LangGraph workflow
‚îÇ   ‚îî‚îÄ‚îÄ agents/               # Plug-and-play agents
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ domain_guard.py   # Policy scope checker
‚îÇ       ‚îú‚îÄ‚îÄ retriever_agent.py # RAG document retriever
‚îÇ       ‚îî‚îÄ‚îÄ summarizer_agent.py # Response generator
‚îÇ
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ chat_api.py           # FastAPI endpoints
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ conversation.py       # SQLAlchemy models (PostgreSQL)
‚îÇ
‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ conversation.py       # Pydantic schemas
‚îÇ
‚îú‚îÄ‚îÄ memory/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ short_term_memory.py  # Redis-based session memory
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ db.py                 # PostgreSQL connection
‚îÇ   ‚îî‚îÄ‚îÄ settings.py           # Environment variables
‚îÇ
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ llm_client.py         # Gemini API client
‚îÇ   ‚îú‚îÄ‚îÄ logger.py             # Logging setup
‚îÇ   ‚îî‚îÄ‚îÄ redis_client.py       # Redis connection
‚îÇ
‚îî‚îÄ‚îÄ main.py                   # FastAPI application
```

## üîß Components

### 1. Orchestrator (`app/orchestrator/orchestrator.py`)

**LangGraph-based workflow manager**

- Built with `langgraph.graph.StateGraph`
- Manages agent execution flow
- Provides both standard and streaming processing
- Easy to extend with new agents

**Key Methods:**
- `process(user_id, message, session_id)` - Standard synchronous processing
- `stream_process(user_id, message, session_id)` - Streaming response processing

### 2. Agents (`app/orchestrator/agents/`)

#### DomainGuard Agent
- **Purpose**: Classify queries as "policy-related" or "off-topic"
- **LLM**: Uses Gemini for intelligent classification
- **Output**: Updates state with classification

#### Retriever Agent
- **Purpose**: Retrieve relevant policy documents
- **Technology**: Vector search (ChromaDB/FAISS - to be integrated)
- **Output**: Retrieved documents and formatted context

#### Summarizer Agent
- **Purpose**: Generate final responses
- **Modes**:
  - Policy-related: Uses retrieved context to answer
  - Off-topic: Returns soft refusal with helpful warning
- **Streaming**: Supports async streaming responses

### 3. State Management

#### Short-Term Memory (Redis)
- Session-based conversation history
- Fast access for real-time chat
- TTL-based expiration (configurable)
- Managed by `app/memory/short_term_memory.py`

#### Long-Term Storage (PostgreSQL)
- Persistent conversation history
- Analytics and reporting
- Two tables:
  - `conversations` - Individual messages
  - `conversation_sessions` - Session metadata

### 4. API Endpoints

**POST /api/chat/**
- Standard chat endpoint
- Returns complete response
- Saves to both Redis and PostgreSQL

**POST /api/chat/stream**
- Streaming chat endpoint
- SSE-compatible
- Real-time token-by-token response

**GET /api/chat/history/{session_id}**
- Retrieve conversation history
- Fetches from PostgreSQL

## üîå Plug-and-Play Agent System

### Adding a New Agent

1. **Create Agent File**
```python
# app/orchestrator/agents/my_new_agent.py

from app.orchestrator.state import AgentState
from app.utils.logger import get_logger

logger = get_logger(__name__)

class MyNewAgent:
    def __call__(self, state: AgentState) -> AgentState:
        # Your agent logic here
        logger.info("MyNewAgent: Processing...")

        # Update state
        state["some_field"] = "some_value"

        return state

# Singleton
my_new_agent = MyNewAgent()
```

2. **Update State Schema** (if needed)
```python
# app/orchestrator/state.py

class AgentState(TypedDict):
    # ... existing fields ...
    some_field: Optional[str]  # Add new field
```

3. **Register in Orchestrator**
```python
# app/orchestrator/orchestrator.py

from app.orchestrator.agents import my_new_agent

def _build_graph(self):
    workflow = StateGraph(AgentState)

    # Add your new node
    workflow.add_node("my_new_agent", my_new_agent)

    # Add edges
    workflow.add_edge("some_node", "my_new_agent")
    workflow.add_edge("my_new_agent", "next_node")
```

## üóÑÔ∏è Database Models

### Conversation
```python
{
    "id": int,
    "session_id": str,
    "user_id": str,
    "role": str,  # "user" or "assistant"
    "message": str,
    "classification": str,  # "policy-related", "off-topic"
    "metadata": dict,  # JSON field
    "created_at": datetime
}
```

### ConversationSession
```python
{
    "id": int,
    "session_id": str,
    "user_id": str,
    "message_count": int,
    "is_active": bool,
    "started_at": datetime,
    "last_activity_at": datetime,
    "ended_at": datetime
}
```

## üß™ Testing

### Test Orchestrator
```bash
python -m tests.test_new_orchestrator
```

### Test LLM Client
```bash
python -m tests.test_llm
```

### Test Redis STM
```bash
python -m tests.redis_stm
```

## üöÄ Running the Application

### Development
```bash
uvicorn app.main:app --reload --port 8000
```

### Production
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

## üìù Environment Variables

Required in `.env`:
```bash
# App
APP_NAME=RAG-based Chatbot
APP_ENV=development
APP_PORT=8000

# PostgreSQL
DATABASE_URL=postgresql://user:pass@host:port/db

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_USERNAME=default
REDIS_PASSWORD=your_password
REDIS_DB=0
REDIS_USE_TLS=false

# Gemini API
GEMINI_API_KEY=your_api_key
GEMINI_MODEL_NAME=gemini-2.5-flash

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/app_logs.log

# Memory Config
MAX_SESSION_MESSAGES=200
SESSION_TTL_DAYS=30
```

## üîÆ Future Enhancements

- [ ] Integrate ChromaDB/FAISS for actual vector search
- [ ] Add document ingestion pipeline
- [ ] Implement feedback mechanism
- [ ] Add analytics dashboard
- [ ] Support for document upload
- [ ] Multi-language support
- [ ] Add more specialized agents (e.g., AnalyticsAgent, FeedbackAgent)

## üìö Tech Stack

- **Framework**: FastAPI
- **Orchestration**: LangGraph
- **LLM**: Google Gemini
- **Vector DB**: ChromaDB/FAISS (planned)
- **Cache**: Redis
- **Database**: PostgreSQL
- **ORM**: SQLAlchemy
- **Validation**: Pydantic
